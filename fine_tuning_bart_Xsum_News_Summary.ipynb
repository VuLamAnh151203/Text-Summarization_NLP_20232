{
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 791838,
          "sourceType": "datasetVersion",
          "datasetId": 1895
        },
        {
          "sourceId": 7980167,
          "sourceType": "datasetVersion",
          "datasetId": 4696739
        }
      ],
      "dockerImageVersionId": 30674,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1.Import the library"
      ],
      "metadata": {
        "id": "oJgFfnL_jn3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets"
      ],
      "metadata": {
        "id": "WqZk53oOWoac",
        "outputId": "fdb82011-0dfe-4aac-9270-5f777ed3f321",
        "execution": {
          "iopub.status.busy": "2024-04-11T08:24:01.157784Z",
          "iopub.execute_input": "2024-04-11T08:24:01.158455Z",
          "iopub.status.idle": "2024-04-11T08:24:14.531810Z",
          "shell.execute_reply.started": "2024-04-11T08:24:01.158415Z",
          "shell.execute_reply": "2024-04-11T08:24:14.530573Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->datasets) (2024.3.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install rouge_score\n",
        "!pip install bert_score"
      ],
      "metadata": {
        "id": "GQirZewrkDhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
        "import nltk\n",
        "from nltk import sent_tokenize\n",
        "import datasets\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        ")\n",
        "\n",
        "from bert_score import BERTScorer\n"
      ],
      "metadata": {
        "id": "-oBHjzXhkMd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.Import the datasets"
      ],
      "metadata": {
        "id": "ziCDxm_AQtGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_csv = pd.read_csv(\"/kaggle/input/news-summary/news_summary.csv\", encoding = \"latin-1\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T14:32:02.514867Z",
          "iopub.execute_input": "2024-04-10T14:32:02.515764Z",
          "iopub.status.idle": "2024-04-10T14:32:02.661360Z",
          "shell.execute_reply.started": "2024-04-10T14:32:02.515727Z",
          "shell.execute_reply": "2024-04-10T14:32:02.660304Z"
        },
        "trusted": true,
        "id": "erXPJ8FbjSya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_csv = dataset_csv.dropna()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T14:32:04.047679Z",
          "iopub.execute_input": "2024-04-10T14:32:04.048397Z",
          "iopub.status.idle": "2024-04-10T14:32:04.058752Z",
          "shell.execute_reply.started": "2024-04-10T14:32:04.048361Z",
          "shell.execute_reply": "2024-04-10T14:32:04.057723Z"
        },
        "trusted": true,
        "id": "_e1MUqWLjSya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = dataset_csv[\"ctext\"]\n",
        "summary = dataset_csv[\"text\"]\n",
        "dataset = Dataset.from_dict({\"document\" : document, \"summary\" : summary})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T14:32:05.514272Z",
          "iopub.execute_input": "2024-04-10T14:32:05.514745Z",
          "iopub.status.idle": "2024-04-10T14:32:05.548498Z",
          "shell.execute_reply.started": "2024-04-10T14:32:05.514714Z",
          "shell.execute_reply": "2024-04-10T14:32:05.547482Z"
        },
        "trusted": true,
        "id": "LAJBz-XsjSyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Max number of token in text: \")\n",
        "print(max(len(x.split()) for x in dataset[\"document\"]))\n",
        "print(\"Max number of token in summary: \")\n",
        "print(max(len(x.split()) for x in dataset[\"summary\"]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T14:33:39.345099Z",
          "iopub.execute_input": "2024-04-10T14:33:39.345901Z",
          "iopub.status.idle": "2024-04-10T14:33:39.481714Z",
          "shell.execute_reply.started": "2024-04-10T14:33:39.345864Z",
          "shell.execute_reply": "2024-04-10T14:33:39.480737Z"
        },
        "trusted": true,
        "id": "zKqcHVEqjSyb",
        "outputId": "1fc5c341-6ce8-46b7-8a89-8dadf079388f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Max number of token in text: \n12202\nMax number of token in summary: \n62\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset = dataset.shuffle(seed=42).select(range(1000))\n",
        "training_dataset = dataset.shuffle(seed = 42).select(range(1001,4396,1))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T14:35:27.386564Z",
          "iopub.execute_input": "2024-04-10T14:35:27.387265Z",
          "iopub.status.idle": "2024-04-10T14:35:27.403144Z",
          "shell.execute_reply.started": "2024-04-10T14:35:27.387231Z",
          "shell.execute_reply": "2024-04-10T14:35:27.402454Z"
        },
        "trusted": true,
        "id": "h_KXVxx8jSyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.Create a strong baseline: base-3 line\n"
      ],
      "metadata": {
        "id": "rewL8qc7jSyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_score = evaluate.load(\"rouge\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T14:28:01.511361Z",
          "iopub.execute_input": "2024-04-10T14:28:01.511704Z",
          "iopub.status.idle": "2024-04-10T14:28:23.849379Z",
          "shell.execute_reply.started": "2024-04-10T14:28:01.511675Z",
          "shell.execute_reply": "2024-04-10T14:28:23.848586Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "690d0865711d4891ab0124a4bc64d997"
          ]
        },
        "id": "cFOs94PfjSye",
        "outputId": "34df6c93-ecf1-4ad0-8e88-a40968f68643"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2024-04-10 14:28:04.966969: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-10 14:28:04.967085: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-10 14:28:05.241203: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "690d0865711d4891ab0124a4bc64d997"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T14:28:23.850522Z",
          "iopub.execute_input": "2024-04-10T14:28:23.851080Z",
          "iopub.status.idle": "2024-04-10T14:28:24.081181Z",
          "shell.execute_reply.started": "2024-04-10T14:28:23.851055Z",
          "shell.execute_reply": "2024-04-10T14:28:24.080111Z"
        },
        "trusted": true,
        "id": "jPLvEjAqjSye",
        "outputId": "d6c489b1-852b-471a-cc57-9dc7e89e8395"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n",
          "output_type": "stream"
        },
        {
          "execution_count": 40,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def three_sentences_summary(text):\n",
        "    return \"\\n\".join(sent_tokenize(text)[:3])\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T14:28:24.083880Z",
          "iopub.execute_input": "2024-04-10T14:28:24.084748Z",
          "iopub.status.idle": "2024-04-10T14:28:24.089314Z",
          "shell.execute_reply.started": "2024-04-10T14:28:24.084700Z",
          "shell.execute_reply": "2024-04-10T14:28:24.088370Z"
        },
        "trusted": true,
        "id": "6HeQWXTOjSyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_baseline(dataset, metric):\n",
        "    summaries = [three_sentences_summary(text) for text in dataset[\"document\"]]\n",
        "    return metric.compute(predictions=summaries, references=dataset[\"summary\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T14:28:24.090394Z",
          "iopub.execute_input": "2024-04-10T14:28:24.090720Z",
          "iopub.status.idle": "2024-04-10T14:28:24.102449Z",
          "shell.execute_reply.started": "2024-04-10T14:28:24.090696Z",
          "shell.execute_reply": "2024-04-10T14:28:24.101689Z"
        },
        "trusted": true,
        "id": "oJVklG86jSyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = evaluate_baseline(validation_dataset,rouge_score)\n",
        "print(\"The base line score:\\n\",score)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T14:35:35.987781Z",
          "iopub.execute_input": "2024-04-10T14:35:35.988142Z",
          "iopub.status.idle": "2024-04-10T14:35:45.511805Z",
          "shell.execute_reply.started": "2024-04-10T14:35:35.988115Z",
          "shell.execute_reply": "2024-04-10T14:35:45.510847Z"
        },
        "trusted": true,
        "id": "NpG1zslYjSyf",
        "outputId": "f04ed286-85b0-41ee-ba16-3d87a266709d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "The base line score:\n {'rouge1': 0.4389851343605487, 'rouge2': 0.2400983572098281, 'rougeL': 0.31238678399992753, 'rougeLsum': 0.3376194701143866}\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.Tokenize the text"
      ],
      "metadata": {
        "id": "BBuyZfV5jSyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"sshleifer/distilbart-xsum-12-3\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "dooE7MmWQwEm",
        "execution": {
          "iopub.status.busy": "2024-04-10T14:35:31.252773Z",
          "iopub.execute_input": "2024-04-10T14:35:31.253686Z",
          "iopub.status.idle": "2024-04-10T14:35:31.478415Z",
          "shell.execute_reply.started": "2024-04-10T14:35:31.253652Z",
          "shell.execute_reply": "2024-04-10T14:35:31.477598Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_max_length = 1024 # demo\n",
        "decoder_max_length = 128"
      ],
      "metadata": {
        "id": "u15kwjA66_Hv",
        "execution": {
          "iopub.status.busy": "2024-04-10T14:35:49.289950Z",
          "iopub.execute_input": "2024-04-10T14:35:49.290699Z",
          "iopub.status.idle": "2024-04-10T14:35:49.294748Z",
          "shell.execute_reply.started": "2024-04-10T14:35:49.290663Z",
          "shell.execute_reply": "2024-04-10T14:35:49.293884Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n",
        "    source, target = batch[\"document\"], batch[\"summary\"]\n",
        "    source_tokenized = tokenizer(\n",
        "        source, padding=\"max_length\", truncation=True, max_length=max_source_length\n",
        "    )\n",
        "    target_tokenized = tokenizer(\n",
        "        target, padding=\"max_length\", truncation=True, max_length=max_target_length\n",
        "    )\n",
        "\n",
        "    batch = {k: v for k, v in source_tokenized.items()}\n",
        "    # Ignore padding in the loss\n",
        "    batch[\"labels\"] = [\n",
        "        [-100 if token == tokenizer.pad_token_id else token for token in l]\n",
        "        for l in target_tokenized[\"input_ids\"]\n",
        "    ]\n",
        "    return batch\n",
        "\n",
        "\n",
        "train_data_token = training_dataset.map(\n",
        "    lambda batch: batch_tokenize_preprocess(\n",
        "        batch, tokenizer, encoder_max_length, decoder_max_length\n",
        "    ),\n",
        "    batched=True,\n",
        "    remove_columns=training_dataset.column_names,\n",
        ")\n",
        "\n",
        "validation_data_token = validation_dataset.map(\n",
        "    lambda batch: batch_tokenize_preprocess(\n",
        "        batch, tokenizer, encoder_max_length, decoder_max_length\n",
        "    ),\n",
        "    batched=True,\n",
        "    remove_columns=validation_dataset.column_names,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "uOSfFXD47R6l",
        "outputId": "3f965afb-6abc-4dd8-b336-38c6137cd80a",
        "execution": {
          "iopub.status.busy": "2024-04-10T14:36:10.847011Z",
          "iopub.execute_input": "2024-04-10T14:36:10.847534Z",
          "iopub.status.idle": "2024-04-10T14:36:17.072934Z",
          "shell.execute_reply.started": "2024-04-10T14:36:10.847500Z",
          "shell.execute_reply": "2024-04-10T14:36:17.071959Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "99f28d1e90c64eadafc5da55b1caa95b",
            "5bf1b7b9d83b46c59c8c586fb4381f0e"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/4 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99f28d1e90c64eadafc5da55b1caa95b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bf1b7b9d83b46c59c8c586fb4381f0e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_token.set_format(\"torch\")\n",
        "validation_data_token.set_format(\"torch\")"
      ],
      "metadata": {
        "id": "pwNserWcanM-",
        "execution": {
          "iopub.status.busy": "2024-04-10T14:36:24.793193Z",
          "iopub.execute_input": "2024-04-10T14:36:24.793887Z",
          "iopub.status.idle": "2024-04-10T14:36:24.799566Z",
          "shell.execute_reply.started": "2024-04-10T14:36:24.793850Z",
          "shell.execute_reply": "2024-04-10T14:36:24.798435Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.Fine-tuning model"
      ],
      "metadata": {
        "id": "mpA6cERZM31z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BartForConditionalGeneration.from_pretrained(\"sshleifer/distilbart-xsum-12-3\")"
      ],
      "metadata": {
        "id": "CK0BmO79cZjw",
        "execution": {
          "iopub.status.busy": "2024-04-10T14:43:32.782688Z",
          "iopub.execute_input": "2024-04-10T14:43:32.783113Z",
          "iopub.status.idle": "2024-04-10T14:43:33.629861Z",
          "shell.execute_reply.started": "2024-04-10T14:43:32.783081Z",
          "shell.execute_reply": "2024-04-10T14:43:33.623074Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "k3Ooq4ziQ78K",
        "outputId": "d78c9c4d-0c9c-4f3d-d517-bafff1a3dd4b",
        "execution": {
          "iopub.status.busy": "2024-04-10T14:43:33.984652Z",
          "iopub.execute_input": "2024-04-10T14:43:33.985020Z",
          "iopub.status.idle": "2024-04-10T14:43:34.247768Z",
          "shell.execute_reply.started": "2024-04-10T14:43:33.984992Z",
          "shell.execute_reply": "2024-04-10T14:43:34.246584Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 89,
          "output_type": "execute_result",
          "data": {
            "text/plain": "BartForConditionalGeneration(\n  (model): BartModel(\n    (shared): Embedding(50264, 1024, padding_idx=1)\n    (encoder): BartEncoder(\n      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x BartEncoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): BartDecoder(\n      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-2): 3 x BartDecoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.object = np.object_"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T14:36:38.330882Z",
          "iopub.execute_input": "2024-04-10T14:36:38.331167Z",
          "iopub.status.idle": "2024-04-10T14:36:38.335327Z",
          "shell.execute_reply.started": "2024-04-10T14:36:38.331143Z",
          "shell.execute_reply": "2024-04-10T14:36:38.334478Z"
        },
        "trusted": true,
        "id": "VWGaQMPHjSyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nltk.download(\"punkt\", quiet=True)\n",
        "\n",
        "\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [label.strip() for label in labels]\n",
        "\n",
        "    # rougeLSum expects newline after each sentence\n",
        "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
        "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "\n",
        "    metric = datasets.load_metric(\"rouge\")\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    preds = np.array(preds)\n",
        "    preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.array(labels)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(\n",
        "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
        "    )\n",
        "    # Extract a few results from ROUGE\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "\n",
        "    prediction_lens = [\n",
        "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
        "    ]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T14:36:43.613039Z",
          "iopub.execute_input": "2024-04-10T14:36:43.613415Z",
          "iopub.status.idle": "2024-04-10T14:36:43.624820Z",
          "shell.execute_reply.started": "2024-04-10T14:36:43.613385Z",
          "shell.execute_reply": "2024-04-10T14:36:43.623903Z"
        },
        "trusted": true,
        "id": "U_8gYbshjSyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"results\",\n",
        "    num_train_epochs=5,  # demo\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    per_device_train_batch_size=4,  # demo\n",
        "    per_device_eval_batch_size=4,\n",
        "    learning_rate=3e-05,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.1,\n",
        "    label_smoothing_factor=0.1,\n",
        "    predict_with_generate=True,\n",
        "    generation_num_beams = 3,\n",
        "    logging_dir=\"logs\",\n",
        "    logging_steps=50,\n",
        "    save_total_limit=3,\n",
        "    generation_max_length = 500,\n",
        "    evaluation_strategy = \"epoch\"\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_data_token,\n",
        "    eval_dataset=validation_data_token,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T14:43:53.624298Z",
          "iopub.execute_input": "2024-04-10T14:43:53.624702Z",
          "iopub.status.idle": "2024-04-10T14:43:53.645223Z",
          "shell.execute_reply.started": "2024-04-10T14:43:53.624670Z",
          "shell.execute_reply": "2024-04-10T14:43:53.644232Z"
        },
        "trusted": true,
        "id": "s0gWpd6fjSyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model before training\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T14:37:52.770211Z",
          "iopub.execute_input": "2024-04-10T14:37:52.770624Z",
          "iopub.status.idle": "2024-04-10T14:42:53.686377Z",
          "shell.execute_reply.started": "2024-04-10T14:37:52.770591Z",
          "shell.execute_reply": "2024-04-10T14:42:53.685497Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "e4aa211486894799a556d47b1c438339"
          ]
        },
        "id": "324K-NbSjSyj",
        "outputId": "3bdb9b52-d8bc-434a-ab3c-77c5f4baf7c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [32/32 04:08]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4aa211486894799a556d47b1c438339"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "  ········································\n"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.16.4"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20240410_144221-xc14yxj4</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/la-team/huggingface/runs/xc14yxj4' target=\"_blank\">olive-smoke-5</a></strong> to <a href='https://wandb.ai/la-team/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/la-team/huggingface' target=\"_blank\">https://wandb.ai/la-team/huggingface</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/la-team/huggingface/runs/xc14yxj4' target=\"_blank\">https://wandb.ai/la-team/huggingface/runs/xc14yxj4</a>"
          },
          "metadata": {}
        },
        {
          "execution_count": 84,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'eval_loss': 5.84979772567749,\n 'eval_rouge1': 26.0381,\n 'eval_rouge2': 9.0818,\n 'eval_rougeL': 18.6491,\n 'eval_rougeLsum': 21.6728,\n 'eval_gen_len': 26.511,\n 'eval_runtime': 262.0025,\n 'eval_samples_per_second': 3.817,\n 'eval_steps_per_second': 0.122}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#start traning the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T14:43:56.556428Z",
          "iopub.execute_input": "2024-04-10T14:43:56.556841Z",
          "iopub.status.idle": "2024-04-10T16:23:02.485779Z",
          "shell.execute_reply.started": "2024-04-10T14:43:56.556811Z",
          "shell.execute_reply": "2024-04-10T16:23:02.484807Z"
        },
        "trusted": true,
        "id": "BW0pbrisjSyk",
        "outputId": "4d1b0e57-b043-4cdf-a790-7937d9f3eed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='2125' max='2125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2125/2125 1:39:02, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3.481200</td>\n      <td>3.320873</td>\n      <td>47.722600</td>\n      <td>26.328200</td>\n      <td>35.506300</td>\n      <td>42.542600</td>\n      <td>66.523000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.226900</td>\n      <td>3.183790</td>\n      <td>50.427100</td>\n      <td>27.704700</td>\n      <td>37.263800</td>\n      <td>45.189700</td>\n      <td>77.115000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.950400</td>\n      <td>3.140087</td>\n      <td>50.636200</td>\n      <td>28.277300</td>\n      <td>37.600000</td>\n      <td>45.490100</td>\n      <td>74.992000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2.801400</td>\n      <td>3.134555</td>\n      <td>51.294200</td>\n      <td>28.468400</td>\n      <td>38.087700</td>\n      <td>46.038600</td>\n      <td>74.299000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.710000</td>\n      <td>3.142618</td>\n      <td>51.270100</td>\n      <td>28.357500</td>\n      <td>37.926300</td>\n      <td>45.893400</td>\n      <td>75.777000</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 62, 'min_length': 11, 'early_stopping': True, 'num_beams': 6, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 62, 'min_length': 11, 'early_stopping': True, 'num_beams': 6, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 62, 'min_length': 11, 'early_stopping': True, 'num_beams': 6, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 62, 'min_length': 11, 'early_stopping': True, 'num_beams': 6, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n",
          "output_type": "stream"
        },
        {
          "execution_count": 94,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainOutput(global_step=2125, training_loss=3.143825220444623, metrics={'train_runtime': 5945.0054, 'train_samples_per_second': 2.855, 'train_steps_per_second': 0.357, 'total_flos': 2.102041116672e+16, 'train_loss': 3.143825220444623, 'epoch': 5.0})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#After training:\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T16:59:58.235389Z",
          "iopub.execute_input": "2024-04-10T16:59:58.235853Z",
          "iopub.status.idle": "2024-04-10T17:06:39.441216Z",
          "shell.execute_reply.started": "2024-04-10T16:59:58.235813Z",
          "shell.execute_reply": "2024-04-10T17:06:39.440092Z"
        },
        "trusted": true,
        "id": "yQXMVpe5jSyl",
        "outputId": "8b8b503c-4cd9-43d4-c2a8-86673a69744b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "execution_count": 147,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'eval_loss': 3.142617702484131,\n 'eval_rouge1': 51.2701,\n 'eval_rouge2': 28.3575,\n 'eval_rougeL': 37.9263,\n 'eval_rougeLsum': 45.8934,\n 'eval_gen_len': 75.777,\n 'eval_runtime': 401.1911,\n 'eval_samples_per_second': 2.493,\n 'eval_steps_per_second': 0.312,\n 'epoch': 5.0}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6.Inference\n"
      ],
      "metadata": {
        "id": "ZXwQo7fdjSyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scorer = BERTScorer(lang=\"en\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T16:50:04.920029Z",
          "iopub.execute_input": "2024-04-10T16:50:04.920985Z",
          "iopub.status.idle": "2024-04-10T16:50:06.085011Z",
          "shell.execute_reply.started": "2024-04-10T16:50:04.920948Z",
          "shell.execute_reply": "2024-04-10T16:50:06.083891Z"
        },
        "trusted": true,
        "id": "JuSz6VKwjSym",
        "outputId": "97419446-5f43-4410-9b95-ec57cd03ce33"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def inference_label(index_document, data_tokenized, data_text, metric_rouge, bert_score):\n",
        "    input_token = data_tokenized[index_document]\n",
        "    prediction = trainer.predict([input_token], max_length = 500, num_beams = 4) .predictions\n",
        "    predicted_summary = tokenizer.decode(prediction[0][2:-1:1])\n",
        "    labels = input_token[\"labels\"]\n",
        "    labels = np.array(labels)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.decode(labels, skip_special_tokens=True)\n",
        "    recall, precision, f1 = bert_score.score([predicted_summary], [decoded_labels])\n",
        "    print(\"The truth summary:\\n\",decoded_labels)\n",
        "    print(\"The predicted summary:\\n\", predicted_summary)\n",
        "    print(\"----------------------------------------------\")\n",
        "    print(\"The rouge score:\", metric_rouge.compute(predictions= [predicted_summary], references=[decoded_labels]))\n",
        "    print(f\"Bert score recall f1 : {float(f1)}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-11T07:58:35.083990Z",
          "iopub.execute_input": "2024-04-11T07:58:35.084778Z",
          "iopub.status.idle": "2024-04-11T07:58:35.093172Z",
          "shell.execute_reply.started": "2024-04-11T07:58:35.084742Z",
          "shell.execute_reply": "2024-04-11T07:58:35.091868Z"
        },
        "trusted": true,
        "id": "Pc7SqBFAjSym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference_label(6, validation_data_token, validation_dataset, rouge_score, scorer)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T16:57:57.280827Z",
          "iopub.execute_input": "2024-04-10T16:57:57.281642Z",
          "iopub.status.idle": "2024-04-10T16:57:58.760305Z",
          "shell.execute_reply.started": "2024-04-10T16:57:57.281605Z",
          "shell.execute_reply": "2024-04-10T16:57:58.759244Z"
        },
        "trusted": true,
        "id": "kUBVmQAJjSyn",
        "outputId": "7e42e6e2-ede0-4126-b341-9d51dd09be12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "The truth summary:\n Tagging Prime Minister Narendra Modi, Canadian Prime Minister Justin Trudeau on Friday re-tweeted a post about Indian tennis player Rohan Bopanna and Canadian player Gabriela Dabrowski. The two had won the mixed doubles title at the French Open. Modi replied, \"India & Canada is an ace partnership, advantageous to both nations, beneficial for the world. Game, set and match always.\"\nThe predicted summary:\n Canadian Prime Minister Justin Trudeau has proposed an India-Canada partnership after Indian tennis player Rohan Bopanna and Canada's Gabriela Dabrowski won the mixed doubles French Open title in June. \"India & Canada is an ace partnership, advantageous to both nations, beneficial for the world,\" tweeted Trudeau.\n----------------------------------------------\nThe rouge score: {'rouge1': 0.6542056074766355, 'rouge2': 0.5142857142857143, 'rougeL': 0.6168224299065421, 'rougeLsum': 0.6168224299065421}\nBert score recall f1 : 0.9357349276542664\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inference with new text:\n",
        "def inference(text, tokenizer,model, num_beams = 5, max_generation_length = 200):\n",
        "    text_tokenized = tokenizer(\n",
        "        [text], padding=\"max_length\", truncation=True, max_length=1024,return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    prediction_token = model.generate(text_tokenized[\"input_ids\"], max_length = max_generation_length, num_beams = num_beams)\n",
        "\n",
        "    prediction_summary = tokenizer.decode(prediction_token[0][2:-1:1])\n",
        "\n",
        "    print(\"The result:\")\n",
        "\n",
        "    print(\"- The original text:\\n\")\n",
        "    print(text)\n",
        "    print(\"-\" * 50)\n",
        "    print(\"- The summary text:\\n\")\n",
        "    print(prediction_summary)\n",
        "\n",
        "    return prediction_summary\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-11T08:25:01.002610Z",
          "iopub.execute_input": "2024-04-11T08:25:01.003610Z",
          "iopub.status.idle": "2024-04-11T08:25:01.010862Z",
          "shell.execute_reply.started": "2024-04-11T08:25:01.003571Z",
          "shell.execute_reply": "2024-04-11T08:25:01.009810Z"
        },
        "trusted": true,
        "id": "9_ZCJOI-jSyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_text1 = \"\"\"\n",
        "Workplace well-being is on an \"upward trajectory\" throughout Asia-Pacific, with Vietnam (65.09) leading the region, according to a recent study by Asia's largest mental health care company Intellect.\n",
        "Other leading countries include Thailand (65.01), the Philippines (64.44), Malaysia (64.22), Singapore (63.98), Japan (63.77), China (63.61), and Indonesia (63.55).\n",
        "\n",
        "Meanwhile, others such as India, Australia and the Republic of Korea are below average though there is potential for further development, the report found.\n",
        "\n",
        "The study uncovered the strengths and areas of improvement of workforces across Asia-Pacific on both individual and organizational levels.\n",
        "\n",
        "While individuals are self-aware, able to build workplace relationships, and likely to encourage workforce participation, they may need support with stress management, emotional regulation, and mental well-being. For organizations in these markets, organizational support is on the rise though companies may need support in implementing employee well-being programmes, Intellect noted.\n",
        "\n",
        "The three sectors with the highest organizational health scores are healthcare and pharmaceuticals (67.48), government and nonprofit (66.81), and education (65.76). All of those are above the overall benchmark score of 63.85.\n",
        "\n",
        "Other above-average industries include technology and telecommunications, professional services, and manufacturing, according to Intellect.\n",
        "\"\"\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T17:28:31.402202Z",
          "iopub.execute_input": "2024-04-10T17:28:31.402946Z",
          "iopub.status.idle": "2024-04-10T17:28:31.409873Z",
          "shell.execute_reply.started": "2024-04-10T17:28:31.402913Z",
          "shell.execute_reply": "2024-04-10T17:28:31.408889Z"
        },
        "trusted": true,
        "id": "nUPRpjoojSyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference(original_text1, tokenizer, trainer.model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T17:28:32.515302Z",
          "iopub.execute_input": "2024-04-10T17:28:32.516008Z",
          "iopub.status.idle": "2024-04-10T17:28:33.393706Z",
          "shell.execute_reply.started": "2024-04-10T17:28:32.515971Z",
          "shell.execute_reply": "2024-04-10T17:28:33.392510Z"
        },
        "trusted": true,
        "id": "h1WjgMUIjSyo",
        "outputId": "d455cadf-7291-4e8b-8bfb-5444c772d82d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "The result:\n- The original text:\n\n\nWorkplace well-being is on an \"upward trajectory\" throughout Asia-Pacific, with Vietnam (65.09) leading the region, according to a recent study by Asia's largest mental health care company Intellect.\nOther leading countries include Thailand (65.01), the Philippines (64.44), Malaysia (64.22), Singapore (63.98), Japan (63.77), China (63.61), and Indonesia (63.55).\n\nMeanwhile, others such as India, Australia and the Republic of Korea are below average though there is potential for further development, the report found.\n\nThe study uncovered the strengths and areas of improvement of workforces across Asia-Pacific on both individual and organizational levels.\n\nWhile individuals are self-aware, able to build workplace relationships, and likely to encourage workforce participation, they may need support with stress management, emotional regulation, and mental well-being. For organizations in these markets, organizational support is on the rise though companies may need support in implementing employee well-being programmes, Intellect noted.\n\nThe three sectors with the highest organizational health scores are healthcare and pharmaceuticals (67.48), government and nonprofit (66.81), and education (65.76). All of those are above the overall benchmark score of 63.85.\n\nOther above-average industries include technology and telecommunications, professional services, and manufacturing, according to Intellect.\n\n--------------------------------------------------\n- The summary text:\n\nWorkplace well-being is on an \"upward trajectory\" across Asia-Pacific, with Vietnam leading the region, according to a report by Asia's largest mental health care company Intellect. Meanwhile, others such as India, Australia and the Republic of Korea are below average, the report found.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_text2 = \"\"\"\n",
        "In the 86th minute of the game on Monday night, when Al Nassr were trailing 0-2 to Al Hilal, Ronaldo and defender Ali Al-Bulaihi went for the ball for a throw-in. Ronaldo got the ball and intended to make a quick throw, but the Saudi Arabian player rushed forward to take it because he thought the throw-in belonged to Al Hilal. But Ronaldo, captain of Al Nassr gritted his teeth and put his elbow out to prevent Al-Bulaihi from stealing the ball. Just as Bulaihi rushed forward, Ronaldo's elbow hit the 35-year-old defender’s neck and he fell down in pain.\n",
        "\n",
        "Referee Mohammed Al-Hoaish immediately gave Ronaldo a red card and sent him off. The Portuguese superstar was surprised, raised his fist towards Al-Hoaish and intended to punch him. At that time, the referee turned away and did not see Ronaldo's threatening action.\n",
        "\n",
        "This is the 12th red card in Ronaldo's career and the first time he has been sent off since 2018. On his way out, Ronaldo pointed at the referee, clapped mockingly and gave him a thumbs up. The 39-year-old striker is set to face suspension for this series of actions.\n",
        "\n",
        "Al-Bulaihi has repeatedly provoked Ronaldo in the Saudi derby games between Al Nassr and Al Hilal. One time he dived then stood up and Ronaldo ran after him and applauded. Al-Bulaihi also provoked Lionel Messi several times, when Saudi Arabia unexpectedly beat Argentina 2-1 in the opening match of the 2022 World Cup.\n",
        "\n",
        "Ronaldo lacked restraint when he encountered many difficulties against the Al Hilal, the team that hold the world record of winning 33 consecutive games in all competitions. He missed a relevant chance in the 17th minute, with a shot that went over the bar. According to Sofascore statistics, Ronaldo only had 33 touches on the ball in 86 minutes of play, missed six shots, had six wrong passes and lost the ball nine times.\n",
        "\n",
        "Al Hilal are the team with the richest tradition in Asia with 66 official titles, including title records in the AFC Champions League and Saudi Pro League. Coach Jorge Jesus's team are ranked 39th in the world, above Marseille, Villarreal or Wolverhampton, according to the power index of Opta. Meanwhile, Al Nassr are 89th, behind Nottingham Forest.\n",
        "\n",
        "The defeat against Al Hilal left Al Nassr with an only chance to get a title this season, which is the King Cup, a tournament similar to England's FA Cup. Al Nassr reached the semifinals and will meet Al Ittihad on April 30. Meanwhile, Al Hilal reached the final of the Saudi Super Cup and will play Al Ittihad on April 11.\n",
        "\"\"\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-11T08:24:22.873199Z",
          "iopub.execute_input": "2024-04-11T08:24:22.873576Z",
          "iopub.status.idle": "2024-04-11T08:24:22.880455Z",
          "shell.execute_reply.started": "2024-04-11T08:24:22.873547Z",
          "shell.execute_reply": "2024-04-11T08:24:22.879382Z"
        },
        "trusted": true,
        "id": "g15zCE8zjSyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference(original_text2, tokenizer, trainer.model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T17:35:33.816573Z",
          "iopub.execute_input": "2024-04-10T17:35:33.817563Z",
          "iopub.status.idle": "2024-04-10T17:35:34.596745Z",
          "shell.execute_reply.started": "2024-04-10T17:35:33.817524Z",
          "shell.execute_reply": "2024-04-10T17:35:34.595656Z"
        },
        "trusted": true,
        "id": "WQROJ3sUjSyr",
        "outputId": "11594d7e-beec-44ac-fd64-cf3e8f165fa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "The result:\n- The original text:\n\n\nIn the 86th minute of the game on Monday night, when Al Nassr were trailing 0-2 to Al Hilal, Ronaldo and defender Ali Al-Bulaihi went for the ball for a throw-in. Ronaldo got the ball and intended to make a quick throw, but the Saudi Arabian player rushed forward to take it because he thought the throw-in belonged to Al Hilal. But Ronaldo, captain of Al Nassr gritted his teeth and put his elbow out to prevent Al-Bulaihi from stealing the ball. Just as Bulaihi rushed forward, Ronaldo's elbow hit the 35-year-old defender’s neck and he fell down in pain.\n\nReferee Mohammed Al-Hoaish immediately gave Ronaldo a red card and sent him off. The Portuguese superstar was surprised, raised his fist towards Al-Hoaish and intended to punch him. At that time, the referee turned away and did not see Ronaldo's threatening action.\n\nThis is the 12th red card in Ronaldo's career and the first time he has been sent off since 2018. On his way out, Ronaldo pointed at the referee, clapped mockingly and gave him a thumbs up. The 39-year-old striker is set to face suspension for this series of actions.\n\nAl-Bulaihi has repeatedly provoked Ronaldo in the Saudi derby games between Al Nassr and Al Hilal. One time he dived then stood up and Ronaldo ran after him and applauded. Al-Bulaihi also provoked Lionel Messi several times, when Saudi Arabia unexpectedly beat Argentina 2-1 in the opening match of the 2022 World Cup.\n\nRonaldo lacked restraint when he encountered many difficulties against the Al Hilal, the team that hold the world record of winning 33 consecutive games in all competitions. He missed a relevant chance in the 17th minute, with a shot that went over the bar. According to Sofascore statistics, Ronaldo only had 33 touches on the ball in 86 minutes of play, missed six shots, had six wrong passes and lost the ball nine times.\n\nAl Hilal are the team with the richest tradition in Asia with 66 official titles, including title records in the AFC Champions League and Saudi Pro League. Coach Jorge Jesus's team are ranked 39th in the world, above Marseille, Villarreal or Wolverhampton, according to the power index of Opta. Meanwhile, Al Nassr are 89th, behind Nottingham Forest.\n\nThe defeat against Al Hilal left Al Nassr with an only chance to get a title this season, which is the King Cup, a tournament similar to England's FA Cup. Al Nassr reached the semifinals and will meet Al Ittihad on April 30. Meanwhile, Al Hilal reached the final of the Saudi Super Cup and will play Al Ittihad on April 11.\n\n--------------------------------------------------\n- The summary text:\n\n Portuguese striker Cristiano Ronaldo was sent off for the 12th time in his career after his elbow hit Al Nassr's defender Ali Al-Bulaihi's neck in the 86th minute of the Saudi Super Cup on Monday night. Ronaldo raised his fist towards referee Mohammed Al-Hoaish and intended to punch him. The referee gave him a red card and sent him off.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_text3 = \"\"\"\n",
        "Holding a high school diploma from Canada and a university degree in Chinese commerce language from China, Tat Dat has faced difficulties securing a fulfilling job upon his return to Vietnam.\n",
        "After moving back to his hometown of northern Quang Ninh province in 2022, it took him four months and over 20 job applications to land a position in e-commerce, with a starting salary of VND8 million ($320) per month - less than he hoped for.\n",
        "\n",
        "\"I diligently monitored job platforms every hour, in search of an e-commerce trade position, hoping for a monthly salary of VND12 million to VND20 million,\" Dat said. \"Upon eventually securing such a position, the employers informed me that what they could offer me would be VND8 million, a figure not open to negotiation.\"\n",
        "\n",
        "Dat said he believed that the salary he was offered would never compensate for the VND15 billion invested in his education, yet he remained at the position for six months.\n",
        "\n",
        "However, the unsatisfactory salary was merely one of several challenges he encountered in the Vietnamese job market, including difficulties adjusting to workplace culture, being tasked with duties not outlined in his contract, and frequently working overtime without additional compensation.\n",
        "\n",
        "\"In practice, although the company’s policy stated an eight-hour workday, the actual hours frequently extended to 10-12 hours a day, with no additional overtime compensation,\" Dat said. \"This was a stark contrast to my previous experiences where an eight-hour workday strictly meant eight hours, nothing more.\"\n",
        "\n",
        "Dat discovered that being bilingual was no longer a distinctive advantage, facing competition from peers fluent in three or four languages.\n",
        "\n",
        "\"Encountering peers fluent in English, Chinese, Korean, and French made me feel less competent,\" he admitted.\n",
        "\"\"\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T17:42:20.597543Z",
          "iopub.execute_input": "2024-04-10T17:42:20.598010Z",
          "iopub.status.idle": "2024-04-10T17:42:20.608220Z",
          "shell.execute_reply.started": "2024-04-10T17:42:20.597974Z",
          "shell.execute_reply": "2024-04-10T17:42:20.606984Z"
        },
        "trusted": true,
        "id": "WKmZ5Dr-jSys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference(original_text3, tokenizer, trainer.model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T17:42:23.378539Z",
          "iopub.execute_input": "2024-04-10T17:42:23.378978Z",
          "iopub.status.idle": "2024-04-10T17:42:24.251692Z",
          "shell.execute_reply.started": "2024-04-10T17:42:23.378944Z",
          "shell.execute_reply": "2024-04-10T17:42:24.250574Z"
        },
        "trusted": true,
        "id": "ImXQAl4zjSys",
        "outputId": "63683833-38bd-481f-dfbf-fcb02063ba2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "The result:\n- The original text:\n\n\nHolding a high school diploma from Canada and a university degree in Chinese commerce language from China, Tat Dat has faced difficulties securing a fulfilling job upon his return to Vietnam.\nAfter moving back to his hometown of northern Quang Ninh province in 2022, it took him four months and over 20 job applications to land a position in e-commerce, with a starting salary of VND8 million ($320) per month - less than he hoped for.\n\n\"I diligently monitored job platforms every hour, in search of an e-commerce trade position, hoping for a monthly salary of VND12 million to VND20 million,\" Dat said. \"Upon eventually securing such a position, the employers informed me that what they could offer me would be VND8 million, a figure not open to negotiation.\"\n\nDat said he believed that the salary he was offered would never compensate for the VND15 billion invested in his education, yet he remained at the position for six months.\n\nHowever, the unsatisfactory salary was merely one of several challenges he encountered in the Vietnamese job market, including difficulties adjusting to workplace culture, being tasked with duties not outlined in his contract, and frequently working overtime without additional compensation.\n\n\"In practice, although the company’s policy stated an eight-hour workday, the actual hours frequently extended to 10-12 hours a day, with no additional overtime compensation,\" Dat said. \"This was a stark contrast to my previous experiences where an eight-hour workday strictly meant eight hours, nothing more.\"\n\nDat discovered that being bilingual was no longer a distinctive advantage, facing competition from peers fluent in three or four languages.\n\n\"Encountering peers fluent in English, Chinese, Korean, and French made me feel less competent,\" he admitted.\n\n--------------------------------------------------\n- The summary text:\n\nVietnamese man Tat Dat, who has a high school diploma from Canada and a university degree in Chinese commerce language from China, has said that the salary he was offered will never compensate for the VND15 billion invested in his education. \"I diligently monitored job platforms every hour, in search of an e-commerce position, hoping for a monthly salary of VND12 million to VND20 million,\" he added.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7.Push model into Huggingface hub"
      ],
      "metadata": {
        "id": "XIB4ZNVnlGrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub --q"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T17:58:15.398048Z",
          "iopub.execute_input": "2024-04-10T17:58:15.399027Z",
          "iopub.status.idle": "2024-04-10T17:58:27.920274Z",
          "shell.execute_reply.started": "2024-04-10T17:58:15.398984Z",
          "shell.execute_reply": "2024-04-10T17:58:27.919052Z"
        },
        "trusted": true,
        "id": "HOSq-Wo4jSyt",
        "outputId": "9fdb38d7-80e1-47a4-c72e-384289bc30ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !huggingface-cli login --token <Token_API_key>\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T18:08:44.439337Z",
          "iopub.execute_input": "2024-04-10T18:08:44.439771Z",
          "iopub.status.idle": "2024-04-10T18:08:46.414336Z",
          "shell.execute_reply.started": "2024-04-10T18:08:44.439738Z",
          "shell.execute_reply": "2024-04-10T18:08:46.413126Z"
        },
        "trusted": true,
        "id": "RdypXX9ojSyt",
        "outputId": "9d813524-9401-4528-a977-b9a4670b727d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create_repo(\"LA1512/fine-tuned-distilbart-xsum-12-3-news-summary\", private=False)\n",
        "\n",
        "trainer.push_to_hub(\"LA1512/fine-tuned-distilbart-xsum-12-3-news-summary\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T18:15:08.152084Z",
          "iopub.execute_input": "2024-04-10T18:15:08.152479Z",
          "iopub.status.idle": "2024-04-10T18:15:40.774486Z",
          "shell.execute_reply.started": "2024-04-10T18:15:08.152427Z",
          "shell.execute_reply": "2024-04-10T18:15:40.773379Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "fac8d87973da4703a4dd314008e8335a",
            "90323757f95a434ba9a7493dcef47e45",
            "df4c5b1930874a418b3dc362283298fd"
          ]
        },
        "id": "IUwiRNHjjSyt",
        "outputId": "22cf7a30-d024-4f68-ac4c-143528f782f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 62, 'min_length': 11, 'early_stopping': True, 'num_beams': 6, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 2}\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/1.02G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fac8d87973da4703a4dd314008e8335a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "training_args.bin:   0%|          | 0.00/4.98k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90323757f95a434ba9a7493dcef47e45"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df4c5b1930874a418b3dc362283298fd"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 230,
          "output_type": "execute_result",
          "data": {
            "text/plain": "CommitInfo(commit_url='https://huggingface.co/LA1512/results/commit/053244e12579db0d33ce5acb1ec1e7e122207d79', commit_message='LA1512/fine-tuned-distilbart-xsum-12-3-news-summary', commit_description='', oid='053244e12579db0d33ce5acb1ec1e7e122207d79', pr_url=None, pr_revision=None, pr_num=None)"
          },
          "metadata": {}
        }
      ]
    }
  ]
}